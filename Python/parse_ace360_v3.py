# -*- coding: utf-8 -*-
"""
Created on Fri Aug 28 09:00:32 2020

@author: andy
"""

# Generated by Selenium IDE
import pytest
import time
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support import expected_conditions
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
from bs4 import BeautifulSoup
import pandas as pd
import os
import glob
import shutil
import pandas as pd
from pathlib import Path
import re 
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime

from os import path
from docx import Document



# =============================================================================
# Global varaibles
# =============================================================================
question_statistics=pd.DataFrame()
difficult_threshold={"min":0.3,"max":0.9}

# =============================================================================
# Functions
# =============================================================================
def get_file_path(directory_name,filename):    
    director_path=Path(directory_name)
    full_file_path=director_path / filename
    return full_file_path
    

    
# # =============================================================================
# # Import Data  
# # =============================================================================

# select qa.id,qa.questionid,qa.questionusageid,q.name,qa.questionsummary,qa.rightanswer,qa.responsesummary,qa.timemodified,qas.state,qas.fraction,qas.userid, username, from_unixtime(qa.timemodified)
# from {question_attempts} qa
# join {question} as q 
# on qa.questionid = q.id
# join {question_attempt_steps} as qas
# on qas.questionattemptid=qa.id
# join {user} as u
# on qas.userid=u.id
# where qas.state in ('gradedright','gradedwrong')
# order by qa.id 



ace360_filename=get_file_path(r"C:\Users\Andy.JIVEDIVE.000\Accelerate People\Accelerate People - ACE360 Reports","Apps Export.xlsx")


#dataset=pd.read_excel(data_orginal_file, sheet_name="TestData",skiprows=range(1,1))
ace360_data_df=pd.read_excel(ace360_filename)
#attempts_df=attempts_df.sort_values(by=['questionusageid','questionid'])

#Find any rows with duplicate ACE360 ID
count=ace360_data_df.groupby('ACE360 ID').count()
number_of_duplicates=len(count[count['Status'] >1])
print("Number of duplicate [ACE360 ID]:{}".format(number_of_duplicates))

#Check for nulls in the standard
standard_null_status=ace360_data_df['Standard'].isnull()
standard_null_count=len(standard_null_status[standard_null_status == True])
print("Number of duplicate [Standard]:{}".format(standard_null_count))

training_provider_null_status=ace360_data_df['Training Provider Name'].isnull()
training_provider_null_count=len(training_provider_null_status[training_provider_null_status == True])
print("Number of duplicate [Training Provider Name]:{}".format(training_provider_null_count))


#all_data_df=pd.merge(attempts_df,quiz_df,left_on='questionid',right_on='questionid')
#all_data_df=all_data_df.sort_values(by=['questionusageid','questionid'])


# =============================================================================
# Generate cound of correct/incorrect question answer and number of attempts with this question in
# N_1 number of correct responses for this question
# N Total number of attempts at this question in this quiz
# N_H=Number of people in the top quartile grade with the correct answer
# N_L=Number of people in the bottom quartile with the correct answer
# K=Number of test items
# =============================================================================
#N_1=




#Headers and redundant columns
# dataset_cleansed=dataset.iloc[1:,1:]

# #Read in next set of answer
# set=0
# for attempt in dataset_cleansed.iterrows():
#     #print("Set={} Row=<{}>".format(attempt,row))
#     set+=1
#     answers=attempt[1]
#     question_no=1
#     for answer in answers:
#         question_no+=1    
#         print("Attempt[{}] Question[{}] Answer={}".format(set,question_no,answer))

# num_columns=len(dataset_cleansed.columns)
# num_responses=len(dataset_cleansed)

# for column_no in range(0,16):
#     #print(column_no)
#     correct_answer=dataset.iloc[0,column_no+1]
#     questions_responses=dataset.iloc[1:,column_no+1]
#     #print("Q{} Correct Answer={}".format(column_no+1,correct_answer))

#     response_count=correct_responses=questions_responses.value_counts()    
#     try:
#         reponse_count_correct=response_count[correct_answer]
#     except: 
#         reponse_count_correct=0 
#         print("No values")
    
   
        
#     # =============================================================================
#     # Item difficulty P=N1/N
#     # N1=Correct Answers
#     # N=Number of reponses
#     # =============================================================================
#     question_eval="OK"
#     P=reponse_count_correct/num_responses
#     #print("Q{} No correct={} Total={} Difficulty={}".format(column_no+1,reponse_count_correct,num_responses,P))
#     if (P < difficult_threshold.get("min")):
#         #print("Question Too Hard")
#         question_eval="Too-Hard"
#     if (P >difficult_threshold.get("max")):
#         #print("Question Too Easy")
#         question_eval="Too-Easy"
        
#     question_stats={"question":column_no+1,"correct":reponse_count_correct,"total":num_responses,"difficulty":P,"evaluation":question_eval}
#     question_statistics=question_statistics.append(question_stats,ignore_index=True)
#     print(question_stats)
    

#     #print("[{}]".format(questions_responses))
#data_group=dataset.groupby("Standard").count()
#plt.bar(data_group.index,data_group['Apprentice ULN'])
# data_group=data_EPA_bookings.groupby("Grading Received from IA").count()
# fig = plt.figure(figsize=(12,10), dpi=800)
# plt.title('Count of P/M/D',fontsize=18) 
# plt.xlabel("Grade",fontsize=16)
# plt.ylabel("Count",fontsize=16)
# plt.xticks(rotation=90)
# plt.bar(data_group.index,data_group['ULN'])
# fig.savefig("fig2.png")
# plt.show()


